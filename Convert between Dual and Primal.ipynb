{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5281a232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T17:36:07.737839100Z",
     "start_time": "2023-05-05T17:35:57.947436700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy\n",
    "import lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "378bd66f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T21:16:10.382074700Z",
     "start_time": "2023-05-05T21:16:10.327858300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convex program objective value (eq (8)):  0.001079083847223075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Strai\\miniconda3\\envs\\ECE-285-Project\\lib\\site-packages\\cvxpy\\expressions\\expression.py:612: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 37 times so far.\n",
      "\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\Strai\\miniconda3\\envs\\ECE-285-Project\\lib\\site-packages\\cvxpy\\expressions\\expression.py:612: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 38 times so far.\n",
      "\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\Strai\\miniconda3\\envs\\ECE-285-Project\\lib\\site-packages\\cvxpy\\expressions\\expression.py:612: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 39 times so far.\n",
      "\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\Strai\\miniconda3\\envs\\ECE-285-Project\\lib\\site-packages\\cvxpy\\expressions\\expression.py:612: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 40 times so far.\n",
      "\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "## This is a basic CVXPY based implementation on a toy dataset for the paper \n",
    "## \"Neural Networks are Convex Regularizers: Exact Polynomial-time Convex Optimization Formulations for Two-layer Networks\"\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "def drelu(x):\n",
    "    return x>=0\n",
    "n=10\n",
    "d=3\n",
    "X=np.random.randn(n,d-1)\n",
    "X=np.append(X,np.ones((n,1)),axis=1)\n",
    "\n",
    "y=((np.linalg.norm(X[:,0:d-1],axis=1)>1)-0.5)*2\n",
    "beta=1e-4\n",
    "\n",
    "\n",
    "dmat=np.empty((n,0))\n",
    "\n",
    "## Finite approximation of all possible sign patterns\n",
    "for i in range(int(1e2)):\n",
    "    u=np.random.randn(d,1)\n",
    "    dmat=np.append(dmat,drelu(np.dot(X,u)),axis=1)\n",
    "\n",
    "dmat=(np.unique(dmat,axis=1))\n",
    "\n",
    "\n",
    "# Optimal CVX\n",
    "m1=dmat.shape[1]\n",
    "Uopt1=cp.Variable((d,m1))\n",
    "Uopt2=cp.Variable((d,m1))\n",
    "\n",
    "## Below we use hinge loss as a performance metric for binary classification\n",
    "yopt1=cp.Parameter((n,1))\n",
    "yopt2=cp.Parameter((n,1))\n",
    "yopt1=cp.sum(cp.multiply(dmat,(X*Uopt1)),axis=1)\n",
    "yopt2=cp.sum(cp.multiply(dmat,(X*Uopt2)),axis=1)\n",
    "cost=cp.sum(cp.norm2((y - yopt1 + yopt2)) ** 2)/n+beta*(cp.mixed_norm(Uopt1.T,2,1)+cp.mixed_norm(Uopt2.T,2,1))\n",
    "constraints=[]\n",
    "constraints+=[cp.multiply((2*dmat-np.ones((n,m1))),(X*Uopt1))>=0]\n",
    "constraints+=[cp.multiply((2*dmat-np.ones((n,m1))),(X*Uopt2))>=0]\n",
    "prob=cp.Problem(cp.Minimize(cost),constraints)\n",
    "prob.solve()\n",
    "cvx_opt=prob.value\n",
    "print(\"Convex program objective value (eq (8)): \",cvx_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 38])\n",
      "0.0004919954226352274\n",
      "0.0004919904749840498\n",
      "0.0004919855273328722\n",
      "0.0004919806960970163\n",
      "0.0004919758648611605\n",
      "0.0004919710336253047\n",
      "0.0004919664934277534\n",
      "0.0004919617786072195\n",
      "0.0004919571802020073\n",
      "0.0004919525817967951\n",
      "0.0004919480998069048\n",
      "0.0004919435014016926\n",
      "0.0004919390194118023\n",
      "0.0004919346538372338\n",
      "0.0004919302300550044\n",
      "0.0004919259226880968\n",
      "0.0004919214989058673\n",
      "0.0004919173661619425\n",
      "0.0004919131170026958\n",
      "0.0004919088096357882\n",
      "0.0004919045604765415\n",
      "0.0004919004859402776\n",
      "0.0004918964114040136\n",
      "0.0004918922204524279\n",
      "0.0004918882041238248\n",
      "0.0004918841877952218\n",
      "0.0004918801714666188\n",
      "0.0004918762715533376\n",
      "0.0004918724880553782\n",
      "0.0004918684717267752\n",
      "0.0004918646300211549\n",
      "0.0004918609047308564\n",
      "0.000491857121232897\n",
      "0.0004918533959425986\n",
      "0.0004918496124446392\n",
      "0.0004918459453620017\n",
      "0.0004918422782793641\n",
      "0.0004918385529890656\n",
      "0.0004918350023217499\n",
      "0.0004918315098620951\n",
      "0.0004918279009871185\n",
      "0.0004918244085274637\n",
      "0.0004918209160678089\n",
      "0.000491817481815815\n",
      "0.0004918140475638211\n",
      "0.0004918105551041663\n",
      "0.0004918071790598333\n",
      "0.0004918038030155003\n",
      "0.0004918003687635064\n",
      "0.0004917971673421562\n",
      "0.0004917938495054841\n",
      "0.000491790589876473\n",
      "0.00049178721383214\n",
      "0.0004917840124107897\n",
      "0.0004917806945741177\n",
      "0.0004917775513604283\n",
      "0.0004917743499390781\n",
      "0.0004917711485177279\n",
      "0.0004917681799270213\n",
      "0.0004917650367133319\n",
      "0.0004917620099149644\n",
      "0.0004917588084936142\n",
      "0.0004917557816952467\n",
      "0.0004917526966892183\n",
      "0.0004917497280985117\n",
      "0.000491746817715466\n",
      "0.0004917438491247594\n",
      "0.0004917408805340528\n",
      "0.0004917379119433463\n",
      "0.0004917351179756224\n",
      "0.0004917321493849158\n",
      "0.0004917292972095311\n",
      "0.0004917264450341463\n",
      "0.0004917235928587615\n",
      "0.0004917207406833768\n",
      "0.0004917179467156529\n",
      "0.00049171521095559\n",
      "0.0004917124169878662\n",
      "0.0004917096812278032\n",
      "0.0004917070618830621\n",
      "0.0004917043261229992\n",
      "0.0004917015903629363\n",
      "0.0004916989128105342\n",
      "0.0004916962934657931\n",
      "0.0004916936159133911\n",
      "0.00049169099656865\n",
      "0.0004916883772239089\n",
      "0.0004916858160868287\n",
      "0.0004916833131574094\n",
      "0.0004916807520203292\n",
      "0.00049167824909091\n",
      "0.0004916756879538298\n",
      "0.0004916732432320714\n",
      "0.0004916706238873303\n",
      "0.0004916681791655719\n",
      "0.0004916657926514745\n",
      "0.0004916632897220552\n",
      "0.0004916608450002968\n",
      "0.0004916584584861994\n",
      "0.000491656013764441\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ True,  True, False,  True,  True, False, False,  True,  True,  True,\n          True, False, False, False,  True,  True,  True,  True, False, False,\n          True, False, False,  True,  True, False, False, False,  True, False,\n          True,  True, False, False, False, False, False, False],\n        [ True, False,  True,  True,  True, False, False, False,  True, False,\n          True,  True, False,  True,  True, False, False, False,  True,  True,\n         False,  True,  True, False, False,  True, False,  True,  True, False,\n          True,  True,  True, False, False,  True,  True, False],\n        [ True, False, False, False, False, False, False, False, False, False,\n         False, False, False, False,  True,  True,  True, False,  True,  True,\n          True,  True,  True,  True,  True, False, False, False, False, False,\n          True,  True,  True, False, False, False, False, False],\n        [ True, False,  True,  True,  True,  True,  True,  True, False, False,\n         False,  True,  True, False,  True, False,  True, False,  True, False,\n         False,  True,  True,  True, False, False,  True, False, False, False,\n          True,  True,  True,  True,  True,  True,  True, False],\n        [ True, False, False,  True,  True, False,  True,  True, False,  True,\n         False, False,  True, False,  True, False, False, False,  True, False,\n         False,  True,  True, False, False, False,  True, False, False, False,\n          True,  True,  True,  True, False, False, False, False],\n        [ True, False, False,  True,  True, False, False, False, False,  True,\n         False, False, False,  True,  True, False, False, False,  True,  True,\n         False,  True,  True, False, False,  True,  True, False, False,  True,\n         False, False,  True, False, False, False, False, False],\n        [ True, False, False,  True,  True,  True,  True, False, False, False,\n         False, False,  True, False,  True,  True,  True, False,  True,  True,\n          True,  True,  True,  True, False, False, False, False, False, False,\n          True,  True,  True,  True,  True,  True, False, False],\n        [ True, False,  True,  True,  True, False, False,  True,  True,  True,\n         False,  True, False,  True,  True,  True,  True, False,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n          True,  True,  True, False, False, False, False, False],\n        [ True,  True, False,  True,  True,  True,  True,  True, False,  True,\n          True, False,  True,  True,  True, False, False, False, False, False,\n         False,  True,  True, False, False,  True,  True, False,  True,  True,\n          True,  True,  True,  True,  True,  True, False, False],\n        [ True, False, False, False,  True,  True,  True,  True, False, False,\n         False, False,  True, False,  True, False,  True, False,  True, False,\n         False, False,  True, False, False, False,  True, False, False, False,\n          True,  True,  True,  True,  True,  True, False, False]])"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch_x = torch.from_numpy(X).float()\n",
    "torch_y = torch.from_numpy(y).float()\n",
    "torch_dmat = torch.from_numpy(dmat).float()\n",
    "torch_v = torch.nn.Parameter(data=torch.from_numpy(Uopt1.value).float(), requires_grad=True)\n",
    "torch_w = torch.nn.Parameter(data=torch.from_numpy(Uopt2.value).float(), requires_grad=True)\n",
    "print(torch_v.shape)\n",
    "step_size = 1e-3\n",
    "previous_loss = 1000\n",
    "for _ in range(100):\n",
    "    V = torch.sum(torch.multiply(torch_dmat, (torch_x @ torch_v)), axis=1)\n",
    "    W = torch.sum(torch.multiply(torch_dmat, (torch_x @ torch_w)), axis=1)\n",
    "    yhat = V - W\n",
    "\n",
    "    temp = torch.sum(torch.linalg.norm(torch_y - yhat) ** 2) / n\n",
    "    temp = temp + beta * (torch.linalg.norm(torch_v.T) + torch.linalg.norm(torch_w.T))\n",
    "    print(temp.item())\n",
    "    temp.backward()\n",
    "    torch_w.data = torch_w.data - step_size * torch_w.grad.data\n",
    "    torch_v.data = torch_v.data - step_size * torch_v.grad.data\n",
    "\n",
    "    torch_w.grad.zero_()\n",
    "    torch_v.grad.zero_()\n",
    "\n",
    "\n",
    "    previous_loss = temp.item()\n",
    "\n",
    "\n",
    "V1 = torch.sum(torch.multiply(torch_dmat, (torch_x @ torch_v)), axis=1)\n",
    "W1 = torch.sum(torch.multiply(torch_dmat, (torch_x @ torch_w)), axis=1)\n",
    "V1 - W1\n",
    "\n",
    "torch.multiply((2*torch_dmat-torch.ones((n,m1))),(torch_x @ torch_v))>=0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-05T21:51:04.925041400Z",
     "start_time": "2023-05-05T21:51:04.871201900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc6deb4",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-05-05T17:36:10.860760Z",
     "start_time": "2023-05-05T17:36:10.762986200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((10, 37), (10, 37))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X @ Uopt1.value).shape, dmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1b8f0224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T21:19:26.008259Z",
     "start_time": "2023-05-05T21:19:25.995214200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 1.00014247,  1.00020982, -0.99925715,  0.99975448, -0.99929034,\n        -0.99857581,  0.99882351,  0.99861577, -1.00085644, -0.99907474]),\n array([ 1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.]),\n tensor([ 1.0000,  1.0002, -0.9995,  1.0000, -0.9996, -0.9990,  0.9991,  0.9990,\n         -1.0008, -0.9992], grad_fn=<SubBackward0>))"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.random.randn(*Uopt1.value.shape)\n",
    "v = np.random.randn(*Uopt2.value.shape)\n",
    "U = np.sum(np.multiply(dmat, (X @ Uopt1.value)), axis=1)\n",
    "V = np.sum(np.multiply(dmat, (X @ Uopt2.value)), axis=1)\n",
    "U - V, y, V1 - W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fcea04d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T17:36:10.915883600Z",
     "start_time": "2023-05-05T17:36:10.825326600Z"
    }
   },
   "outputs": [],
   "source": [
    "def h(X, W1, W2):\n",
    "    Z = X @ W1.T\n",
    "    return np.max(Z, 0) @ W2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89f4fc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T17:36:10.934461700Z",
     "start_time": "2023-05-05T17:36:10.851719700Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu_solution_mapping(weights, remove_sparse: bool = False):\n",
    "    assert len(weights.shape) == 4\n",
    "\n",
    "    weight_norms = (lab.sum(weights ** 2, axis=-1, keepdims=True)) ** (1 / 4)\n",
    "    normalized_weights = lab.safe_divide(weights, weight_norms)\n",
    "\n",
    "    num_classes = weights.shape[1]\n",
    "    first_layer = None\n",
    "    second_layer = []\n",
    "    for c in range(num_classes):\n",
    "        pre_zeros = [\n",
    "            lab.zeros_like(weight_norms[0, c]) for i in range(2 * c)\n",
    "        ]  # positive neurons\n",
    "        post_zeros = [\n",
    "            lab.zeros_like(weight_norms[0, c])\n",
    "            for i in range(2 * (num_classes - c - 1))\n",
    "        ]\n",
    "\n",
    "        if first_layer is None:\n",
    "            pre_weights = []\n",
    "        else:\n",
    "            pre_weights = [first_layer]\n",
    "\n",
    "        first_layer = lab.concatenate(\n",
    "            pre_weights\n",
    "            + [\n",
    "                normalized_weights[0][c],\n",
    "                normalized_weights[1][c],\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        w2 = lab.concatenate(\n",
    "            pre_zeros\n",
    "            + [\n",
    "                weight_norms[0][c],\n",
    "                -weight_norms[1][c],\n",
    "            ]\n",
    "            + post_zeros,\n",
    "            axis=0,\n",
    "        ).T\n",
    "        second_layer.append(w2)\n",
    "\n",
    "    second_layer = lab.concatenate(second_layer, axis=0)\n",
    "\n",
    "    if remove_sparse:\n",
    "        sparse_indices = lab.sum(first_layer, axis=1) != 0\n",
    "\n",
    "        first_layer = first_layer[sparse_indices]\n",
    "        second_layer = second_layer[:, sparse_indices]\n",
    "\n",
    "    return first_layer, second_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7173e82c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T21:19:40.760513500Z",
     "start_time": "2023-05-05T21:19:40.748439500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8943468481849357\n"
     ]
    },
    {
     "data": {
      "text/plain": "(2, 1, 38, 3)"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch_w.detach().numpy()\n",
    "v = torch_v.detach().numpy()\n",
    "print(np.sum(u - Uopt1.value))\n",
    "weights = np.asarray([u.T[np.newaxis, ...], v.T[np.newaxis, ...]])\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2743c317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T21:19:48.019132800Z",
     "start_time": "2023-05-05T21:19:48.008119400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((76, 3), (1, 76))"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer, second_layer = relu_solution_mapping(weights)\n",
    "first_layer.shape, second_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c06de817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T21:21:35.630127300Z",
     "start_time": "2023-05-05T21:21:35.622573800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array([-1.00008394, -1.00024645,  0.99923569, -0.9998878 ,  0.99932438,\n         0.99858516, -0.99885033, -0.99857286,  1.00086481,  0.99896518]),\n array([-1.0000315 , -1.0002092 ,  0.9994532 , -0.99995315,  0.9996407 ,\n         0.9989744 , -0.99906576, -0.9990246 ,  1.0008032 ,  0.9991805 ],\n       dtype=float32))"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = np.maximum(X @ first_layer.T, 0) @ second_layer.T\n",
    "y_hat.flatten(), (W1 - V1).detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776210bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T17:36:11.116285800Z",
     "start_time": "2023-05-05T17:36:10.965005800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "9.431263687803744"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(y_hat - y) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc98fe70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T17:36:11.197754700Z",
     "start_time": "2023-05-05T17:36:10.994552200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([5.35196622e-05, 8.84419883e-05, 5.37521787e-05, 2.07437063e-04,\n       1.00073661e-04, 1.05839852e-04, 1.06817992e-04, 5.99995749e-05,\n       3.66983459e-04, 3.21400563e-04, 3.75653638e-01, 1.31702164e+00,\n       8.08135707e-05, 9.29051668e-05, 7.26736617e-05, 6.52529665e-05,\n       5.09129867e-05, 4.75941400e-05, 5.87642561e-05, 8.50540817e-01,\n       7.66011602e-01, 3.08373013e-04, 1.07950341e-04, 1.16344173e+00,\n       7.45397194e-05, 2.37792862e-04, 7.94876247e-05, 7.26755656e-05,\n       1.33518825e-03, 1.33518682e-03, 7.49985581e-05, 3.85312993e-05,\n       6.26299270e-05, 5.99172624e-05, 3.81812373e-05, 6.39062917e-05,\n       4.81448639e-05, 5.35196622e-05, 5.16749107e-05, 5.33242822e-05,\n       4.78307743e-05, 5.17301424e-05, 4.94403369e-05, 4.45873737e-05,\n       5.41328079e-05, 3.95143690e-05, 4.12333694e-05, 3.78057851e-05,\n       3.93295325e-05, 5.03331748e-05, 4.59129701e-05, 1.60853516e-04,\n       9.47347835e-05, 1.27411479e-04, 2.88111964e-04, 5.21693194e-05,\n       4.72334343e-05, 4.82138880e-05, 3.90981113e-05, 4.55386327e-05,\n       4.10354741e-05, 4.72515233e-05, 4.03288791e-05, 4.36488610e-05,\n       4.50123501e-05, 3.97199002e-05, 4.69060640e-05, 1.25820773e-04,\n       2.32845310e-04, 1.88466737e-04, 5.02103889e-05, 1.46388906e-03,\n       1.58662600e-04, 1.49095005e+00])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(first_layer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8984da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T17:36:11.236161800Z",
     "start_time": "2023-05-05T17:36:11.025870700Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2869790986.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"C:\\Users\\Strai\\AppData\\Local\\Temp\\ipykernel_14008\\2869790986.py\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    np.max(1 - np.multiply(y.flatten(), y_hat.flatten())\u001B[0m\n\u001B[1;37m                                                        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "np.max(1 - np.multiply(y.flatten(), y_hat.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c08c4c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-05T17:36:11.047711200Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
